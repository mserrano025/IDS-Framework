{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from h2o.estimators import H2ODeepLearningEstimator\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Server Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"11.0.24\" 2024-07-16; OpenJDK Runtime Environment (build 11.0.24+8-post-Ubuntu-1ubuntu322.04); OpenJDK 64-Bit Server VM (build 11.0.24+8-post-Ubuntu-1ubuntu322.04, mixed mode, sharing)\n",
      "  Starting server from /home/markel/TFM Ciber/IDS-Framework/.venv/lib/python3.10/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpgrba1do7\n",
      "  JVM stdout: /tmp/tmpgrba1do7/h2o_markel_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpgrba1do7/h2o_markel_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Madrid</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 1 day</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_markel_hiwnl3</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>2 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.12 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       Europe/Madrid\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.4\n",
       "H2O_cluster_version_age:    1 month and 1 day\n",
       "H2O_cluster_name:           H2O_from_python_markel_hiwnl3\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    2 Gb\n",
       "H2O_cluster_total_cores:    2\n",
       "H2O_cluster_allowed_cores:  2\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.12 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init(min_mem_size='2G')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of the initial basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "train_files = [\n",
    "    \"CICIDS2017/Monday-WorkingHours.pcap_ISCX.csv\",\n",
    "    \"CICIDS2017/Tuesday-WorkingHours.pcap_ISCX.csv\"\n",
    "]\n",
    "train_frames = []\n",
    "\n",
    "for frame in train_files:\n",
    "    df = pd.read_csv(frame)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    train_frames.append(h2o.H2OFrame(df))\n",
    "train = train_frames[0].rbind(train_frames[1])  # Concatenar H2OFrames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de predictores y respuesta\n",
    "predictors = [\n",
    "    \"Destination Port\", \"Flow Duration\", \"Total Fwd Packets\", \"Total Backward Packets\",\n",
    "    \"Total Length of Fwd Packets\", \"Total Length of Bwd Packets\", \"Fwd Packet Length Max\",\n",
    "    \"Fwd Packet Length Min\", \"Fwd Packet Length Mean\", \"Fwd Packet Length Std\",\n",
    "    \"Bwd Packet Length Max\", \"Bwd Packet Length Min\", \"Bwd Packet Length Mean\",\n",
    "    \"Bwd Packet Length Std\", \"Flow Bytes/s\", \"Flow Packets/s\", \"Flow IAT Mean\",\n",
    "    \"Flow IAT Std\", \"Flow IAT Max\", \"Flow IAT Min\", \"Fwd IAT Total\", \"Fwd IAT Mean\",\n",
    "    \"Fwd IAT Std\", \"Fwd IAT Max\", \"Fwd IAT Min\", \"Bwd IAT Total\", \"Bwd IAT Mean\",\n",
    "    \"Bwd IAT Std\", \"Bwd IAT Max\", \"Bwd IAT Min\", \"Fwd PSH Flags\", \"Bwd PSH Flags\",\n",
    "    \"Fwd URG Flags\", \"Bwd URG Flags\", \"Fwd Header Length\", \"Bwd Header Length\",\n",
    "    \"Fwd Packets/s\", \"Bwd Packets/s\", \"Min Packet Length\", \"Max Packet Length\",\n",
    "    \"Packet Length Mean\", \"Packet Length Std\", \"Packet Length Variance\", \"FIN Flag Count\",\n",
    "    \"SYN Flag Count\", \"RST Flag Count\", \"PSH Flag Count\", \"ACK Flag Count\",\n",
    "    \"URG Flag Count\", \"CWE Flag Count\", \"ECE Flag Count\", \"Down/Up Ratio\",\n",
    "    \"Average Packet Size\", \"Avg Fwd Segment Size\", \"Avg Bwd Segment Size\",\n",
    "    \"Fwd Avg Bytes/Bulk\", \"Fwd Avg Packets/Bulk\", \"Fwd Avg Bulk Rate\",\n",
    "    \"Bwd Avg Bytes/Bulk\", \"Bwd Avg Packets/Bulk\", \"Bwd Avg Bulk Rate\",\n",
    "    \"Subflow Fwd Packets\", \"Subflow Fwd Bytes\", \"Subflow Bwd Packets\",\n",
    "    \"Subflow Bwd Bytes\", \"Init_Win_bytes_forward\", \"Init_Win_bytes_backward\",\n",
    "    \"act_data_pkt_fwd\", \"min_seg_size_forward\", \"Active Mean\", \"Active Std\",\n",
    "    \"Active Max\", \"Active Min\", \"Idle Mean\", \"Idle Std\", \"Idle Max\", \"Idle Min\"\n",
    "]\n",
    "response = \"Label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_automl(train, valid=None, max_runtime_secs=60, checkpoint_model=None):\n",
    "    #TODO: change the checkpoint philosophy, if it exists then load the checkpointed model,\n",
    "    if checkpoint_model:\n",
    "        #load checkpointed model from models folder\n",
    "        aml = h2o.load_model(checkpoint_model)\n",
    "        aml.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n",
    "    else:\n",
    "        aml = H2OAutoML(max_runtime_secs=max_runtime_secs, seed=1234, verbosity=\"info\", nfolds=0, keep_cross_validation_predictions=False,\n",
    "                        include_algos=['DeepLearning', 'DRF'])\n",
    "        aml.train(x=predictors, y=response, training_frame=train, validation_frame=valid)\n",
    "    return aml\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Proccess (skip if already done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "11:14:13.428: Project: AutoML_1_20240811_111413\n",
      "11:14:13.440: Cross-validation disabled by user: no fold column nor nfolds > 1.\n",
      "11:14:15.729: Setting stopping tolerance adaptively based on the training frame: 0.00101231013475982\n",
      "11:14:15.730: Build control seed: 1234\n",
      "11:14:15.751: Since cross-validation is disabled, and validation frame(s) were not provided, automatically split the training data into training, validation frame(s) in the ratio 90/10/0.\n",
      "11:14:30.995: training frame: Frame key: AutoML_1_20240811_111413_training_py_1_sid_86a5    cols: 79    rows: 878311  chunks: 83    size: 237027006  checksum: 1257857219597217920\n",
      "11:14:31.323: validation frame: Frame key: AutoML_1_20240811_111413_validation_py_1_sid_86a5    cols: 79    rows: 97516  chunks: 83    size: 24122433  checksum: -4377021869752132496\n",
      "11:14:31.323: leaderboard frame: Frame key: AutoML_1_20240811_111413_validation_py_1_sid_86a5    cols: 79    rows: 97516  chunks: 83    size: 24122433  checksum: -4377021869752132496\n",
      "11:14:31.324: blending frame: NULL\n",
      "11:14:31.324: response column: Label\n",
      "11:14:31.324: fold column: null\n",
      "11:14:31.324: weights column: null\n",
      "11:14:31.445: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (6g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (6g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (10g, 60w)]}, {StackedEnsemble : [best_of_family_1 (1g, 5w), best_of_family_2 (2g, 5w), best_of_family_3 (3g, 5w), best_of_family_4 (4g, 5w), best_of_family_5 (5g, 5w), all_2 (2g, 10w), all_3 (3g, 10w), all_4 (4g, 10w), all_5 (5g, 10w), monotonic (6g, 10w), best_of_family_gbm (6g, 10w), all_gbm (7g, 10w), best_of_family_xglm (8g, 10w), all_xglm (8g, 10w), best_of_family (10g, 10w), best_N (10g, 10w)]}]\n",
      "11:14:31.547: Disabling Algo: GBM as requested by the user.\n",
      "11:14:31.547: Disabling Algo: XGBoost as requested by the user.\n",
      "11:14:31.547: Disabling Algo: StackedEnsemble as requested by the user.\n",
      "11:14:31.548: Disabling Algo: GLM as requested by the user.\n",
      "11:14:31.562: AutoML job created: 2024.08.11 11:14:13.155\n",
      "11:14:31.569: AutoML build started: 2024.08.11 11:14:31.568\n",
      "11:14:31.571: Skipping StackedEnsemble 'best_of_family_1' due to the exclude_algos option or it is already trained.\n",
      "11:14:31.974: AutoML: starting DRF_1_AutoML_1_20240811_111413 model training\n",
      "11:14:32.130: _train param, Dropping bad and constant columns: [Bwd Avg Packets/Bulk, Fwd URG Flags, Fwd Avg Bulk Rate, Bwd PSH Flags, Bwd URG Flags, CWE Flag Count, Bwd Avg Bytes/Bulk, Fwd Avg Bytes/Bulk, Fwd Avg Packets/Bulk, Bwd Avg Bulk Rate]\n",
      "\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      "11:15:37.287: New leader: DRF_1_AutoML_1_20240811_111413, mean_per_class_error: 0.004215975305750989\n",
      "11:15:37.288: Actual modeling steps: [{DRF : [def_1 (2g, 10w)]}]\n",
      "11:15:37.290: AutoML build stopped: 2024.08.11 11:15:37.288\n",
      "11:15:37.290: AutoML build done: built 1 models\n",
      "11:15:37.290: AutoML duration:  1 min  5.720 sec\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/markel/TFM Ciber/IDS-Framework/models/best_model'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento inicial del modelo\n",
    "aml = train_automl(train)\n",
    "\n",
    "# Guardar el modelo inicial\n",
    "best_model = aml.leader\n",
    "best_model.model_id = \"best_model\"\n",
    "h2o.download_model(model=best_model, path=\"models/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "best_model = h2o.load_model(\"models/best_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Proccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return h2o.H2OFrame(df)\n",
    "\n",
    "# Función para asegurar que los niveles categóricos coincidan\n",
    "def ensure_categorical_levels(train, valid, response):\n",
    "    for col in train.columns:\n",
    "        if train[col].isfactor()[0]:\n",
    "            # Convertir a factor y alinear niveles\n",
    "            valid[col] = valid[col].asfactor()\n",
    "            \n",
    "            # Extraer los niveles como una lista de cadenas\n",
    "            train_levels = train[col].levels()[0]\n",
    "            valid[col] = valid[col].set_levels(train_levels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos de validación\n",
    "valid = load_and_prepare_data(\"CICIDS2017/Wednesday-workingHours.pcap_ISCX.csv\")\n",
    "\n",
    "# Asegurarse de que los niveles categóricos coincidan\n",
    "#ensure_categorical_levels(train, valid, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Realizar predicciones\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(valid)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Convertir predicciones y etiquetas reales a formato de pandas para comparación\u001b[39;00m\n\u001b[1;32m      5\u001b[0m pred_df \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mas_data_frame()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones\n",
    "predictions = best_model.predict(valid)\n",
    "\n",
    "# Convertir predicciones y etiquetas reales a formato de pandas para comparación\n",
    "pred_df = predictions.as_data_frame()['predict']\n",
    "actual_df = valid.as_data_frame()[response]\n",
    "\n",
    "accuracy = accuracy_score(actual_df, pred_df)\n",
    "print(f\"Performance for Wednesday: Accuracy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Decidir si reentrenar\n",
    "if accuracy < 0.95:\n",
    "    print(f\"Retraining model for Wednesday data\")\n",
    "\n",
    "    # Agregar datos del día al conjunto de entrenamiento\n",
    "    train = train.rbind(valid)\n",
    "\n",
    "    # Reentrenar modelo\n",
    "    retrainable_model = h2o.upload_model(\"models/best_model\")\n",
    "\n",
    "    # Comprobar el tipo de modelo y reentrenar\n",
    "    if retrainable_model.algo == \"DeepLearning\":\n",
    "        dl_checkpoint2 = H2ODeepLearningEstimator(\n",
    "            model_id=\"best_model_DL_\" + str(retrainable_model.params['epochs']['actual'] + 1),\n",
    "            checkpoint=retrainable_model.model_id + \"_wednesday\",\n",
    "            epochs=int(retrainable_model.params['epochs']['actual']) + 5,\n",
    "            seed=retrainable_model.params['seed']['actual']\n",
    "        )\n",
    "    elif retrainable_model.algo == \"drf\":\n",
    "        dl_checkpoint2 = H2ORandomForestEstimator(\n",
    "            model_id=\"best_model_forest_\" + str(retrainable_model.params['ntrees']['actual'] + 1),\n",
    "            checkpoint=retrainable_model.model_id + \"_wednesday\",\n",
    "            ntrees=int(retrainable_model.params['ntrees']['actual']) + 5,\n",
    "            seed=retrainable_model.params['seed']['actual']\n",
    "        )\n",
    "\n",
    "    # Entrenar con el conjunto de entrenamiento completo\n",
    "    dl_checkpoint2.train(x=predictors, y=response, training_frame=train)\n",
    "\n",
    "    # Guardar nuevo mejor modelo\n",
    "    best_model_path = h2o.download_model(model=dl_checkpoint2, path=\"models/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_bb46 closed.\n"
     ]
    }
   ],
   "source": [
    "h2o.cluster().shutdown(prompt=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
